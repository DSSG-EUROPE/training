{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification \n",
    "There are a set of documents under two different categories. We perform supervised\n",
    "learning to classify each document into the corret category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all documents from the folder into the memory\n",
      "In total 42 documents loaded\n",
      "21 documents in business categories\n",
      "21 documents in sports categories\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "folder_path = \"data/articles_classified\"\n",
    "assert os.path.exists(folder_path), \"The folder is not found\"\n",
    "\n",
    "try:\n",
    "    print(\"Loading all documents from the folder into the memory\")\n",
    "    documents = load_files(folder_path, shuffle=True, encoding='utf-8')\n",
    "except FileNotFoundError:\n",
    "    print(\"Cannot load the files at '%s'\" % folder_path)\n",
    "else:\n",
    "    print(\"In total %d documents loaded\" % len(documents.data))     \n",
    "    \n",
    "for i, e in enumerate(documents.target_names):\n",
    "    print(\"%d documents in %s categories\" % \n",
    "          (len(documents.target[documents.target == i]), e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprecossing text data \n",
    "We preprocess the raw text and further extract, vectorize\n",
    "and normalize features for classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(documents.data)):\n",
    "    # Normalize words into lowercase\n",
    "    documents.data[i] = documents.data[i].lower()\n",
    "\n",
    "    # Remove punctuations, linebreaks, numbers and short words\n",
    "    symbols = ['[-./?!,\":;()|$\\'\\‚Äù]', \n",
    "                '[\\r?\\n]+', '[0-9]+', \n",
    "                r'\\b[a-zA-Z]{1,3}\\b']\n",
    "    for symbol in symbols :\n",
    "        documents.data[i] = re.sub(symbol, ' ', documents.data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the data into a training set and a test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    documents.data, documents.target, train_size = 0.8, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tokenize the documents into words, and then extract two types of features as\n",
    "bag-of-words (BoW) model.\n",
    "1: CountVectorizer collects token's occurence counts\n",
    "2: TfidfVectorizer collects token's term-frequency and inverted document-frequency\n",
    "We use the default ngram_range=(1,1), and can set (1,2) to account for bigrams.\n",
    "However, given our limited sample size and already large feature dimensions, bigrams\n",
    "or n-grams can be useful for classification tasks that also account for the order of\n",
    "words for larger text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sample: 42, number of features: 1646\n"
     ]
    }
   ],
   "source": [
    "# Tokenizating text and filtering stopwords, rare words and common words\n",
    "# CountVectorizer collects token's occurence counts\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english',\n",
    "                             min_df=2, max_df=0.9)\n",
    "\n",
    "X = vectorizer.fit_transform(documents.data)\n",
    "print(\"Number of sample: %d, number of features: %d\" % X.shape)\n",
    "\n",
    "# TfidfVectorizer collects TF-IDF measures\n",
    "vectorizer_tfidf = TfidfVectorizer(lowercase=True, stop_words='english',\n",
    "                                  min_df=2, max_df=0.9)\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(documents.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying news articles\n",
    "Our task is a typical binary classification with balanced samples in two classes.\n",
    "We use the following classifiers that were commonly used in similar settings to \n",
    "perform the task:\n",
    "1. Logistic Regression\n",
    "2. Naive Bayes (Multinomial, Bernoulli)\n",
    "4. Linear SVM  \n",
    "5. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the training set with each classifier. To reduce overfitting, we introduce \n",
    "regularization terms to penalize the loss function. We use exhaustive grid search \n",
    "to choose hyperparameters for each classifier that has the best cross validation \n",
    "score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator obtained is: \n",
      "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "The best params obtained are: {'clf__C': 0.001, 'clf__penalty': 'l2'}\n",
      "Time used for training and testing: 1.44s\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   business       1.00      1.00      1.00         4\n",
      "     sports       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00         9\n",
      "\n",
      "Confusion matrix:\n",
      "[[4 0]\n",
      " [0 5]]\n",
      "Test accuracy: 1.00\n",
      "Cross-validation accuracy: 0.95 (+/- 0.10)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classifer\n",
    "pipeline_lr = Pipeline([\n",
    "        ('vect', vectorizer),\n",
    "        ('clf', LogisticRegression(multi_class='ovr'))\n",
    "    ])\n",
    "\n",
    "start = time()\n",
    "\n",
    "# Set the dictionairy of hyperparameters\n",
    "parameters_logit = {\n",
    "    'clf__C': [1e-3, 1e-2, 1e-1, 1.0, 10.0],\n",
    "    'clf__penalty': ['l1', 'l2']\n",
    "    }\n",
    "        \n",
    "# Perform grid search over parameter space and obtain the best estimator\n",
    "clf_grid_logit = GridSearchCV(pipeline_lr, \n",
    "                              parameters_logit, \n",
    "                              n_jobs=-1).fit(X_train, y_train)\n",
    "clf_logit = clf_grid_logit.best_estimator_\n",
    "print(\"The best estimator obtained is: \")\n",
    "print(clf_logit._final_estimator)\n",
    "print(\"The best params obtained are: %s\" % clf_grid_logit.best_params_)\n",
    "\n",
    "# Predict the outcome on the test set\n",
    "y_predicted = clf_logit.predict(X_test)\n",
    "\n",
    "# Print the training and testing time\n",
    "print(\"Time used for training and testing: %0.2fs\" % (time() - start))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(y_test, y_predicted, target_names=documents.target_names))\n",
    "# Print and plot the confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "print(cm)\n",
    "\n",
    "#Print the accuracy on left-out test set  \n",
    "print(\"Test accuracy: %0.2f\" % clf_logit.fit(X_train, y_train).score(X_test, y_test)) \n",
    "scores = cross_val_score(clf_logit, X_train, y_train, cv=10)\n",
    "print(\"Cross-validation accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fit other classifiers in a similar fashion. Specifically, we can build\n",
    "a ''pipeline'' for each classifier to allow for chaining multiple transformation\n",
    "and estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator obtained for Multinomial Naive Bayes is: \n",
      "MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True)\n",
      "The best params obtained is: {'clf__alpha': 0.001}\n",
      "Time used for training and testing: 0.83s\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   business       1.00      1.00      1.00         4\n",
      "     sports       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00         9\n",
      "\n",
      "Confusion matrix:\n",
      "[[4 0]\n",
      " [0 5]]\n",
      "Test accuracy: 1.00\n",
      "Cross-validation accuracy: 0.97 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes as classifier\n",
    "pipeline_multinomial_bayes = Pipeline([\n",
    "        ('vect', vectorizer),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "start = time()\n",
    "\n",
    "# Set the dictionairy of hyperparameters for additive smoothing\n",
    "parameters_bayes = {\n",
    "    'clf__alpha': [1e-3, 1e-2, 1e-1, 1.0]\n",
    "    }\n",
    "\n",
    "# Perform grid search over parameter space and obtain the best estimator\n",
    "multinomial_bayes_grid = GridSearchCV(pipeline_multinomial_bayes, \n",
    "                              parameters_bayes, \n",
    "                              n_jobs=-1).fit(X_train, y_train)\n",
    "multinomial_bayes_clf = multinomial_bayes_grid.best_estimator_\n",
    "print(\"The best estimator obtained for Multinomial Naive Bayes is: \")\n",
    "print(multinomial_bayes_clf._final_estimator)\n",
    "print(\"The best params obtained is: %s\" % multinomial_bayes_grid.best_params_)\n",
    "\n",
    "# Predict the outcome on the test set\n",
    "y_predicted = multinomial_bayes_clf.predict(X_test)\n",
    "\n",
    "# Print the training and testing time\n",
    "print(\"Time used for training and testing: %0.2fs\" % (time() - start))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(y_test, y_predicted, target_names=documents.target_names))\n",
    "# Print and plot the confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "print(cm)\n",
    "\n",
    "#Print the accuracy on left-out test set and cross-validation\n",
    "print(\"Test accuracy: %0.2f\" % multinomial_bayes_clf.fit(X_train, y_train).score(X_test, y_test)) \n",
    "scores = cross_val_score(multinomial_bayes_clf, X_train, y_train, cv=10)\n",
    "print(\"Cross-validation accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator obtained for Bernoulli Naive Bayes is: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "The best params obtained is: {'clf__alpha': 0.01}\n",
      "Time used for training and testing: 0.70s\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   business       1.00      1.00      1.00         4\n",
      "     sports       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00         9\n",
      "\n",
      "Confusion matrix:\n",
      "[[4 0]\n",
      " [0 5]]\n",
      "Test accuracy: 1.00\n",
      "Cross-validation accuracy: 1.00 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes as classifier\n",
    "pipeline_bernoulli_bayes = Pipeline([\n",
    "        ('vect', vectorizer),\n",
    "        ('clf', BernoulliNB())\n",
    "    ])\n",
    "\n",
    "start = time()\n",
    "\n",
    "# Set the dictionairy of hyperparameters for additive smoothing\n",
    "parameters_bayes = {\n",
    "    'clf__alpha': [1e-3, 1e-2, 1e-1, 1.0]\n",
    "    }\n",
    "\n",
    "# Perform grid search over parameter space and obtain the best estimator\n",
    "bernoullie_bayes_grid = GridSearchCV(pipeline_bernoulli_bayes, \n",
    "                              parameters_bayes, \n",
    "                              n_jobs=-1).fit(X_train, y_train)\n",
    "bernoulli_bayes_clf = bernoullie_bayes_grid.best_estimator_\n",
    "print(\"The best estimator obtained for Bernoulli Naive Bayes is: \")\n",
    "print(bernoulli_bayes_clf._final_estimator)\n",
    "print(\"The best params obtained is: %s\" % bernoullie_bayes_grid.best_params_)\n",
    "\n",
    "# Predict the outcome on the test set\n",
    "y_predicted = bernoulli_bayes_clf.predict(X_test)\n",
    "\n",
    "# Print the training and testing time\n",
    "print(\"Time used for training and testing: %0.2fs\" % (time() - start))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(y_test, y_predicted, target_names=documents.target_names))\n",
    "# Print and plot the confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "print(cm)\n",
    "\n",
    "#Print the accuracy on left-out test set and cross-validation\n",
    "print(\"Test accuracy: %0.2f\" % bernoulli_bayes_clf.fit(X_train, y_train).score(X_test, y_test)) \n",
    "scores = cross_val_score(bernoulli_bayes_clf, X_train, y_train, cv=10)\n",
    "print(\"Cross-validation accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator obtained for Linear SVM is: \n",
      "LinearSVC(C=0.001, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "The best params obtained is: {'clf__C': 0.001}\n",
      "Time used for training and testing: 0.68s\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   business       1.00      1.00      1.00         4\n",
      "     sports       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00         9\n",
      "\n",
      "Confusion matrix:\n",
      "[[4 0]\n",
      " [0 5]]\n",
      "Test accuracy: 1.00\n",
      "Cross-validation accuracy: 0.97 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM as classifier\n",
    "pipeline_svm = Pipeline([\n",
    "        ('vect', vectorizer),\n",
    "        ('clf', LinearSVC(multi_class='ovr'))\n",
    "    ])\n",
    "\n",
    "start = time()\n",
    "\n",
    "# Set the dictionairy of hyperparameters for C\n",
    "parameters_svm = {\n",
    "    'clf__C': [1e-3, 1e-2, 1e-1, 1.0, 10.0]\n",
    "    }\n",
    "\n",
    "# Perform grid search over parameter space and obtain the best estimator\n",
    "svm_grid = GridSearchCV(pipeline_svm, \n",
    "                              parameters_svm, \n",
    "                              n_jobs=-1).fit(X_train, y_train)\n",
    "svm_clf = svm_grid.best_estimator_\n",
    "print(\"The best estimator obtained for Linear SVM is: \")\n",
    "print(svm_clf._final_estimator)\n",
    "print(\"The best params obtained is: %s\" % svm_grid.best_params_)\n",
    "\n",
    "# Predict the outcome on the test set\n",
    "y_predicted = svm_clf.predict(X_test)\n",
    "\n",
    "# Print the training and testing time\n",
    "print(\"Time used for training and testing: %0.2fs\" % (time() - start))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(y_test, y_predicted, target_names=documents.target_names))\n",
    "# Print and plot the confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "print(cm)\n",
    "\n",
    "#Print the accuracy on left-out test set and cross-validation\n",
    "print(\"Test accuracy: %0.2f\" % svm_clf.fit(X_train, y_train).score(X_test, y_test)) \n",
    "scores = cross_val_score(svm_clf, X_train, y_train, cv=10)\n",
    "print(\"Cross-validation accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator obtained for Random Forests is: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=150, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "The best params obtained is: {'clf__min_samples_leaf': 1, 'clf__max_features': 'log2', 'clf__n_estimators': 150}\n",
      "Time used for training and testing: 17.64s\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   business       1.00      0.75      0.86         4\n",
      "     sports       0.83      1.00      0.91         5\n",
      "\n",
      "avg / total       0.91      0.89      0.89         9\n",
      "\n",
      "Confusion matrix:\n",
      "[[3 1]\n",
      " [0 5]]\n",
      "Test accuracy: 0.89\n",
      "Cross-validation accuracy: 0.97 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "# Random Forests as classifier, note that Random Forest may take long \n",
    "# training time that depends on the number and depth of trees \n",
    "pipeline_rf = Pipeline([\n",
    "        ('vect', vectorizer),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "start = time()\n",
    "\n",
    "# Set the dictionairy of hyperparameters for \n",
    "parameters_rf = {\n",
    "    'clf__max_features': ['sqrt', 'log2', None],\n",
    "    'clf__n_estimators': [30, 50, 100, 150],\n",
    "    'clf__min_samples_leaf': [1, 2, 5, 10]\n",
    "    }\n",
    "\n",
    "# Perform grid search over parameter space and obtain the best estimator\n",
    "rf_grid = GridSearchCV(pipeline_rf, \n",
    "                              parameters_rf, \n",
    "                              n_jobs=-1).fit(X_train, y_train)\n",
    "rf_clf = rf_grid.best_estimator_\n",
    "print(\"The best estimator obtained for Random Forests is: \")\n",
    "print(rf_clf._final_estimator)\n",
    "print(\"The best params obtained is: %s\" % rf_grid.best_params_)\n",
    "\n",
    "# Predict the outcome on the test set\n",
    "y_predicted = rf_clf.predict(X_test)\n",
    "\n",
    "# Print the training and testing time\n",
    "print(\"Time used for training and testing: %0.2fs\" % (time() - start))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(y_test, y_predicted, target_names=documents.target_names))\n",
    "# Print and plot the confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "print(cm)\n",
    "\n",
    "#Print the accuracy on left-out test set and cross-validation\n",
    "print(\"Test accuracy: %0.2f\" % rf_clf.fit(X_train, y_train).score(X_test, y_test)) \n",
    "scores = cross_val_score(rf_clf, X_train, y_train, cv=10)\n",
    "print(\"Cross-validation accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further combine the above classifiers to make a better prediction, \n",
    "e.g., through majority voting mechanism. This is particularly useful when \n",
    "classifiers are performing equally well and voting classifier can balance \n",
    "out their individual weaknesses.\n",
    "\n",
    "We see that linear classifiers generally performs well, as data can be more\n",
    "easily separated linearly in high-dimensional spaces. However, we caution \n",
    "the interpretation of this result to be siginificant given the very limited\n",
    "sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95 (+/- 0.10) [Logistic Regression]\n",
      "Accuracy: 0.97 (+/- 0.07) [Multinomial Naive Bayes]\n",
      "Accuracy: 1.00 (+/- 0.00) [Bernoulli Naive Bayes]\n",
      "Accuracy: 0.97 (+/- 0.07) [Linear SVM]\n",
      "Accuracy: 0.94 (+/- 0.12) [Random Forests]\n",
      "Accuracy: 1.00 (+/- 0.00) [Voting]\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('lr', clf_logit), ('mnnb', multinomial_bayes_clf),\n",
    "                                         ('bnnb', bernoulli_bayes_clf), ('lsvm', svm_clf),\n",
    "                                         ('rf', rf_clf)], voting='hard')\n",
    "\n",
    "for clf, label in zip([clf_logit, multinomial_bayes_clf, bernoulli_bayes_clf, svm_clf, \n",
    "                       rf_clf, voting_clf],\n",
    "                     ['Logistic Regression', 'Multinomial Naive Bayes', 'Bernoulli Naive Bayes',\n",
    "                     'Linear SVM', 'Random Forests', 'Voting']):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper function\n",
    "We can write parameterized wrapper functions for pipelines that\n",
    "are easy to be called, using different feature extractors, classifers,\n",
    "and results reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameterized training model\n",
    "def training(vect, clf, params, X_train, y_train):\n",
    "    print('_' * 80)\n",
    "    print(\"Start training %s: \" % clf.__class__.__name__)\n",
    "    \n",
    "    # Set up the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf', clf)       \n",
    "    ])\n",
    "    \n",
    "    start = time()\n",
    "    \n",
    "    # Set the dictionairy of hyperparameters \n",
    "    params = params\n",
    "    \n",
    "    # Perform grid search over parameter space and obtain the best estimator\n",
    "    grid_search = GridSearchCV(pipeline, params, n_jobs=-1).fit(X_train, y_train)\n",
    "    grid_clf = grid_search.best_estimator_\n",
    "    print(\"The best estimator obtained is: \")\n",
    "    pprint(grid_clf._final_estimator)\n",
    "    print(\"The best params obtained is: %s\" % grid_search.best_params_)\n",
    "    print(\"Time used for training: %0.2fs\" % (time() - start))\n",
    "    return grid_clf\n",
    "\n",
    "# Present evaluation results \n",
    "def evaluation(grid_clf, X_test, y_test):\n",
    "    print(\"Predict the outcome on the test set\")\n",
    "    y_predicted = grid_clf.predict(X_test)\n",
    "\n",
    "    # Print the classification report\n",
    "    print(\"Classification report:\")\n",
    "    print(metrics.classification_report(y_test, y_predicted, target_names=documents.target_names))\n",
    "    # Print and plot the confusion matrix\n",
    "    print(\"Confusion matrix:\")\n",
    "    cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "    print(cm)\n",
    "\n",
    "    #Print the accuracy on left-out test set and cross-validation\n",
    "    print(\"Test accuracy: %0.2f\" % metrics.accuracy_score(y_test, y_predicted)) \n",
    "    scores = cross_val_score(grid_clf, X_train, y_train, cv=10)\n",
    "    print(\"Cross-validation accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we simply call training function to train classification model with \n",
    "specified parameters and save the model and calculate the cross-validation \n",
    "accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Start training LogisticRegression: \n",
      "The best estimator obtained is: \n",
      "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "The best params obtained is: {'clf__C': 0.001, 'clf__penalty': 'l2'}\n",
      "Time used for training: 1.11s\n",
      "Predict the outcome on the test set\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   business       1.00      1.00      1.00         4\n",
      "     sports       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00         9\n",
      "\n",
      "Confusion matrix:\n",
      "[[4 0]\n",
      " [0 5]]\n",
      "Test accuracy: 1.00\n",
      "Cross-validation accuracy: 0.95 (+/- 0.10)\n",
      "________________________________________________________________________________\n",
      "Start training MultinomialNB: \n",
      "The best estimator obtained is: \n",
      "MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True)\n",
      "The best params obtained is: {'clf__alpha': 0.001}\n",
      "Time used for training: 0.56s\n",
      "Predict the outcome on the test set\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   business       1.00      1.00      1.00         4\n",
      "     sports       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00         9\n",
      "\n",
      "Confusion matrix:\n",
      "[[4 0]\n",
      " [0 5]]\n",
      "Test accuracy: 1.00\n",
      "Cross-validation accuracy: 0.97 (+/- 0.07)\n",
      "________________________________________________________________________________\n",
      "Start training BernoulliNB: \n",
      "The best estimator obtained is: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "The best params obtained is: {'clf__alpha': 0.01}\n",
      "Time used for training: 0.89s\n",
      "Predict the outcome on the test set\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   business       1.00      1.00      1.00         4\n",
      "     sports       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00         9\n",
      "\n",
      "Confusion matrix:\n",
      "[[4 0]\n",
      " [0 5]]\n",
      "Test accuracy: 1.00\n",
      "Cross-validation accuracy: 1.00 (+/- 0.00)\n",
      "________________________________________________________________________________\n",
      "Start training LinearSVC: \n",
      "The best estimator obtained is: \n",
      "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "The best params obtained is: {'clf__C': 0.1}\n",
      "Time used for training: 0.68s\n",
      "Predict the outcome on the test set\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   business       1.00      1.00      1.00         4\n",
      "     sports       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00         9\n",
      "\n",
      "Confusion matrix:\n",
      "[[4 0]\n",
      " [0 5]]\n",
      "Test accuracy: 1.00\n",
      "Cross-validation accuracy: 0.97 (+/- 0.07)\n",
      "________________________________________________________________________________\n",
      "Start training RandomForestClassifier: \n",
      "The best estimator obtained is: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=150, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "The best params obtained is: {'clf__min_samples_leaf': 2, 'clf__max_features': 'sqrt', 'clf__n_estimators': 150}\n",
      "Time used for training: 19.26s\n",
      "Predict the outcome on the test set\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   business       1.00      1.00      1.00         4\n",
      "     sports       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00         9\n",
      "\n",
      "Confusion matrix:\n",
      "[[4 0]\n",
      " [0 5]]\n",
      "Test accuracy: 1.00\n",
      "Cross-validation accuracy: 1.00 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "trained_models = []\n",
    "results = []\n",
    "vect_list = [vectorizer, vectorizer, vectorizer_tfidf, vectorizer_tfidf, vectorizer]\n",
    "clf_list = [LogisticRegression(multi_class='ovr'),\n",
    "           MultinomialNB(), BernoulliNB(),\n",
    "           LinearSVC(multi_class='ovr'),\n",
    "           RandomForestClassifier()]\n",
    "params_list = [parameters_logit, parameters_bayes, parameters_bayes,\n",
    "              parameters_svm, parameters_rf]\n",
    "\n",
    "for i, (l1, l2, l3)  in enumerate(zip(vect_list, clf_list, params_list)):\n",
    "    #print(i, l1, l2, l3)\n",
    "    trained_models.append(training(l1, l2, l3, X_train, y_train))\n",
    "    results.append(evaluation(trained_models[i], X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides precision-recall and confusion matrix, we can also visualize\n",
    "the calssifier output quality, e.g, through Receive Operating \n",
    "Characteristic (ROC) curve and area under the curve (AUC). Below\n",
    "shows an example of Logistic Regression, where we obtain the perfect\n",
    "prediction, i.e., AUC = 1 for 100% of test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAGHCAYAAACJeOnXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110702e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predicted = clf_logit.fit(X_train, y_train).predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_predicted)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, lw=2, color='blue',\n",
    "        label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='cyan', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve for Logistic Regression')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train our model using the whole dataset and persist the model \n",
    "for future use without have to retrain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained ad hoc model: MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True)\n",
      "Test accuracy from ad hoc model is 1.00:\n"
     ]
    }
   ],
   "source": [
    "clf_dump = []\n",
    "for trained_model in trained_models:    \n",
    "    clf_dump.append(pickle.dumps(trained_model.fit(documents.data, documents.target)))\n",
    "\n",
    "# Load a trained model for ready use    \n",
    "clf2 = pickle.loads(clf_dump[1])\n",
    "print(\"Trained ad hoc model: %s\" % clf2._final_estimator)\n",
    "print(\"Test accuracy from ad hoc model is %0.2f:\" %  metrics.accuracy_score(y_test, clf2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}